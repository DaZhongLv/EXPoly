{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec4e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvmeizhong/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/lvmeizhong/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "/var/folders/06/hmnjzdgn7vgcwblryw9g856c0000gn/T/ipykernel_29051/1906020755.py:30: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/lvmeizhong/Downloads/edge_diamond_glide_set_dissociated_swapYZ.lmp\n",
      "New bounds:\n",
      "xlo xhi: -75.0470767729 73.787668008\n",
      "ylo yhi: -74.7199654502 82.6373232656\n",
      "zlo zhi: -74.14077634019999 73.6231741509\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# # =========================\n",
    "# # USER CONFIG\n",
    "# # =========================\n",
    "# IN_PATH  = Path(\"/Users/lvmeizhong/Downloads/edge_diamond_glide_set_dissociated.lmp\")  # 改成你的路径\n",
    "# OUT_PATH = IN_PATH.with_name(IN_PATH.stem + \"_swapYZ.lmp\")\n",
    "\n",
    "# PAD = 1e-6          # 给 bounds 加一点点余量，防浮点误差\n",
    "# FLOAT_FMT = \"%.13f\" # 输出坐标精度\n",
    "# # =========================\n",
    "\n",
    "# # --- 1) 找到 Atoms 段起始行号（用于 skiprows） ---\n",
    "# with IN_PATH.open(\"r\") as f:\n",
    "#     lines = f.readlines()\n",
    "\n",
    "# atoms_hdr_idx = None\n",
    "# for i, l in enumerate(lines):\n",
    "#     if l.strip().startswith(\"Atoms\"):\n",
    "#         atoms_hdr_idx = i\n",
    "#         break\n",
    "# assert atoms_hdr_idx is not None, \"没找到 'Atoms' 段\"\n",
    "\n",
    "# # Atoms header 下一行通常是空行；原子数据从 atoms_hdr_idx+2 开始\n",
    "# atoms_data_start = atoms_hdr_idx + 2\n",
    "\n",
    "# # --- 2) 读 Atoms（你的文件是 Atoms # atomic: id type x y z） ---\n",
    "# df = pd.read_csv(\n",
    "#     IN_PATH,\n",
    "#     delim_whitespace=True,\n",
    "#     header=None,\n",
    "#     names=[\"id\", \"type\", \"x\", \"y\", \"z\"],\n",
    "#     skiprows=atoms_data_start,\n",
    "#     comment=\"#\",\n",
    "#     engine=\"python\",\n",
    "# )\n",
    "\n",
    "# # --- 3) swap：把现在的 Y 当 Z，把现在的 Z 当 Y（y<->z） ---\n",
    "# df_sw = df.copy()\n",
    "# df_sw[\"y\"], df_sw[\"z\"] = df[\"z\"], df[\"y\"]\n",
    "\n",
    "# # --- 4) 重新计算交换后的 box bounds（关键：避免越界 wrap 导致“对不齐”） ---\n",
    "# xlo, xhi = df_sw[\"x\"].min() - PAD, df_sw[\"x\"].max() + PAD\n",
    "# ylo, yhi = df_sw[\"y\"].min() - PAD, df_sw[\"y\"].max() + PAD\n",
    "# zlo, zhi = df_sw[\"z\"].min() - PAD, df_sw[\"z\"].max() + PAD\n",
    "\n",
    "# # --- 5) 重写文件：保留原 header/sections，只替换 xlo/xhi,ylo/yhi,zlo/zhi，并写新的 Atoms ---\n",
    "# re_x = re.compile(r\"^\\s*([+-]?\\d.*)\\s+([+-]?\\d.*)\\s+xlo\\s+xhi\\s*$\")\n",
    "# re_y = re.compile(r\"^\\s*([+-]?\\d.*)\\s+([+-]?\\d.*)\\s+ylo\\s+yhi\\s*$\")\n",
    "# re_z = re.compile(r\"^\\s*([+-]?\\d.*)\\s+([+-]?\\d.*)\\s+zlo\\s+zhi\\s*$\")\n",
    "\n",
    "# with OUT_PATH.open(\"w\") as out:\n",
    "#     # 5.1 写 header 到 Atoms header 行（含 Masses 等都原样保留，但 bounds 行替换）\n",
    "#     for i in range(atoms_hdr_idx + 1):  # 包含 \"Atoms  # atomic\" 这一行\n",
    "#         l = lines[i].rstrip(\"\\n\")\n",
    "#         if re_x.match(l):\n",
    "#             out.write(f\"{xlo:{''}.15f} {xhi:{''}.15f} xlo xhi\\n\")\n",
    "#         elif re_y.match(l):\n",
    "#             out.write(f\"{ylo:{''}.15f} {yhi:{''}.15f} ylo yhi\\n\")\n",
    "#         elif re_z.match(l):\n",
    "#             out.write(f\"{zlo:{''}.15f} {zhi:{''}.15f} zlo zhi\\n\")\n",
    "#         else:\n",
    "#             out.write(lines[i])\n",
    "\n",
    "#     # 5.2 确保 Atoms header 后有一个空行（按原文件格式）\n",
    "#     if atoms_hdr_idx + 1 < len(lines) and lines[atoms_hdr_idx + 1].strip() != \"\":\n",
    "#         out.write(\"\\n\")\n",
    "\n",
    "#     # 5.3 写 Atoms 数据（id type x y z）\n",
    "#     #     注意：id/type 保持整数，坐标用 FLOAT_FMT\n",
    "#     df_out = df_sw[[\"id\", \"type\", \"x\", \"y\", \"z\"]].copy()\n",
    "#     df_out[\"id\"] = df_out[\"id\"].astype(int)\n",
    "#     df_out[\"type\"] = df_out[\"type\"].astype(int)\n",
    "\n",
    "#     df_out.to_csv(\n",
    "#         out,\n",
    "#         sep=\" \",\n",
    "#         header=False,\n",
    "#         index=False,\n",
    "#         float_format=FLOAT_FMT,\n",
    "#     )\n",
    "\n",
    "# print(\"Wrote:\", OUT_PATH)\n",
    "# print(\"New bounds:\")\n",
    "# print(\"xlo xhi:\", xlo, xhi)\n",
    "# print(\"ylo yhi:\", ylo, yhi)\n",
    "# print(\"zlo zhi:\", zlo, zhi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1bb099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/hmnjzdgn7vgcwblryw9g856c0000gn/T/ipykernel_29051/3669369442.py:39: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/lvmeizhong/Downloads/edge_diamond_glide_set_swapYZ.lmp\n",
      "natoms: 616824\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG\n",
    "# =========================\n",
    "IN_PATH  = Path(\"/Users/lvmeizhong/Downloads/edge_diamond_glide_set.lmp\")\n",
    "OUT_PATH = IN_PATH.with_name(IN_PATH.stem + \"_swapYZ.lmp\")\n",
    "\n",
    "PAD = 1e-6\n",
    "FLOAT_FMT = \"%.13f\"\n",
    "# =========================\n",
    "\n",
    "with IN_PATH.open(\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# --- NEW: parse natoms from header (one added block) ---\n",
    "natoms = None\n",
    "re_natoms = re.compile(r\"^\\s*(\\d+)\\s+atoms\\s*$\")\n",
    "for l in lines[:2000]:  # header 一般很短，扫前 2000 行足够\n",
    "    m = re_natoms.match(l.strip())\n",
    "    if m:\n",
    "        natoms = int(m.group(1))\n",
    "        break\n",
    "assert natoms is not None, \"Header 里没找到 'N atoms'\"\n",
    "\n",
    "# --- 1) 找到 Atoms 段起始行号 ---\n",
    "atoms_hdr_idx = None\n",
    "for i, l in enumerate(lines):\n",
    "    if l.strip().startswith(\"Atoms\"):\n",
    "        atoms_hdr_idx = i\n",
    "        break\n",
    "assert atoms_hdr_idx is not None, \"没找到 'Atoms' 段\"\n",
    "\n",
    "atoms_data_start = atoms_hdr_idx + 2  # 假设 Atoms header 后有空行\n",
    "\n",
    "# --- 2) 读 Atoms：关键是一行 nrows=natoms（就这行最重要） ---\n",
    "df = pd.read_csv(\n",
    "    IN_PATH,\n",
    "    delim_whitespace=True,\n",
    "    header=None,\n",
    "    names=[\"id\", \"type\", \"x\", \"y\", \"z\"],\n",
    "    skiprows=atoms_data_start,\n",
    "    nrows=natoms,              # <<< 关键：只读 natoms 行 :contentReference[oaicite:3]{index=3}\n",
    "    comment=\"#\",\n",
    "    engine=\"python\",\n",
    ")\n",
    "\n",
    "# --- 3) swap y<->z ---\n",
    "df_sw = df.copy()\n",
    "df_sw[\"y\"], df_sw[\"z\"] = df[\"z\"], df[\"y\"]\n",
    "\n",
    "# --- 4) 重新计算 bounds ---\n",
    "xlo, xhi = df_sw[\"x\"].min() - PAD, df_sw[\"x\"].max() + PAD\n",
    "ylo, yhi = df_sw[\"y\"].min() - PAD, df_sw[\"y\"].max() + PAD\n",
    "zlo, zhi = df_sw[\"z\"].min() - PAD, df_sw[\"z\"].max() + PAD\n",
    "\n",
    "re_x = re.compile(r\"^\\s*([+-]?\\d.*)\\s+([+-]?\\d.*)\\s+xlo\\s+xhi\\s*$\")\n",
    "re_y = re.compile(r\"^\\s*([+-]?\\d.*)\\s+([+-]?\\d.*)\\s+ylo\\s+yhi\\s*$\")\n",
    "re_z = re.compile(r\"^\\s*([+-]?\\d.*)\\s+([+-]?\\d.*)\\s+zlo\\s+zhi\\s*$\")\n",
    "\n",
    "with OUT_PATH.open(\"w\") as out:\n",
    "    # 写 header 到 Atoms header 行（含 Atoms 行本身）\n",
    "    for i in range(atoms_hdr_idx + 1):\n",
    "        l = lines[i].rstrip(\"\\n\")\n",
    "        if re_x.match(l):\n",
    "            out.write(f\"{xlo:.15f} {xhi:.15f} xlo xhi\\n\")\n",
    "        elif re_y.match(l):\n",
    "            out.write(f\"{ylo:.15f} {yhi:.15f} ylo yhi\\n\")\n",
    "        elif re_z.match(l):\n",
    "            out.write(f\"{zlo:.15f} {zhi:.15f} zlo zhi\\n\")\n",
    "        else:\n",
    "            out.write(lines[i])\n",
    "\n",
    "    # 更稳：无条件补一个空行（LAMMPS 数据文件空行很重要）:contentReference[oaicite:4]{index=4}\n",
    "    out.write(\"\\n\")\n",
    "\n",
    "    df_out = df_sw[[\"id\", \"type\", \"x\", \"y\", \"z\"]].copy()\n",
    "    df_out[\"id\"] = df_out[\"id\"].astype(int)\n",
    "    df_out[\"type\"] = df_out[\"type\"].astype(int)\n",
    "\n",
    "    df_out.to_csv(out, sep=\" \", header=False, index=False, float_format=FLOAT_FMT)\n",
    "\n",
    "    # 关键：把原文件 Atoms 段后面的内容原样接回去（如果有的话）\n",
    "    rest_start = atoms_data_start + natoms\n",
    "    out.write(\"\\n\")\n",
    "    out.writelines(lines[rest_start:])\n",
    "\n",
    "print(\"Wrote:\", OUT_PATH)\n",
    "print(\"natoms:\", natoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947fe85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0d647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54478ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvmeizhong/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/lvmeizhong/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m HZ0, HZ1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 如果你的 Frame 类不在 python path，改成你实际 import 路径\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# from expoly.frames import Frame\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mframes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Frame   \u001b[38;5;66;03m# <- 例如你把那份 frames.py 放在当前目录\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 1) 读 HDF5：FeatureIds + DIMENSIONS\u001b[39;00m\n\u001b[1;32m     21\u001b[0m f \u001b[38;5;241m=\u001b[39m Frame(\n\u001b[1;32m     22\u001b[0m     path\u001b[38;5;241m=\u001b[39mDREAM3D_PATH,\n\u001b[1;32m     23\u001b[0m     prefer_groups\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCellData\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCellFeatureData\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_SIMPL_GEOMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m],  \u001b[38;5;66;03m# 和你代码默认一致\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     mapping\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrainId\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatureIds\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIMENSIONS\u001b[39m\u001b[38;5;124m\"\u001b[39m},       \u001b[38;5;66;03m# 只取我们需要的\u001b[39;00m\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/expoly-with-legacy/EXPoly/src/expoly/frames.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m general_func\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ----------------- Common HDF5 helpers -----------------\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_dataset_keys\u001b[39m(f: hdf\u001b[38;5;241m.\u001b[39mFile, target_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     17\u001b[0m                       prefer_groups: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# USER CONFIG\n",
    "# =========================\n",
    "DREAM3D_PATH = Path(\"/Users/lvmeizhong/Downloads/t0_Meshed_MoreFeature.dream3d\")   # 你的 .dream3d/.h5\n",
    "OUT_CSV      = DREAM3D_PATH.with_suffix(\"\").with_name(DREAM3D_PATH.stem + \"_hx70-200_hy70-200_hz150-500.csv\")\n",
    "\n",
    "HX0, HX1 = 70, 200\n",
    "HY0, HY1 = 70, 200\n",
    "HZ0, HZ1 = 150, 500\n",
    "\n",
    "# 如果你的 Frame 类不在 python path，改成你实际 import 路径\n",
    "# from expoly.frames import Frame\n",
    "from frames import Frame  # <- 例如你把那份 frames.py 放在当前目录\n",
    "\n",
    "# =========================\n",
    "\n",
    "# 1) 读 HDF5：FeatureIds + DIMENSIONS\n",
    "f = Frame(\n",
    "    path=DREAM3D_PATH,\n",
    "    prefer_groups=[\"CellData\", \"CellFeatureData\", \"_SIMPL_GEOMETRY\"],  # 和你代码默认一致\n",
    "    mapping={\"GrainId\": \"FeatureIds\", \"Dimension\": \"DIMENSIONS\"},       # 只取我们需要的\n",
    ")\n",
    "\n",
    "dim = np.asarray(f.Dimension).reshape(-1)\n",
    "HX, HY, HZ = int(dim[0]), int(dim[1]), int(dim[2])\n",
    "\n",
    "gid = np.asarray(f.GrainId)\n",
    "# Dream3D/SIMPL 常见：FeatureIds 是长度 HX*HY*HZ 的 1D 数组\n",
    "if gid.ndim == 1:\n",
    "    assert gid.size == HX * HY * HZ, f\"FeatureIds size={gid.size} != HX*HY*HZ={HX*HY*HZ}\"\n",
    "    grid = gid.reshape((HZ, HY, HX), order=\"C\")   # grid[hz,hy,hx]\n",
    "elif gid.ndim == 3:\n",
    "    # 如果已经是 3D，就尽量对齐到 (HZ,HY,HX)\n",
    "    if gid.shape == (HZ, HY, HX):\n",
    "        grid = gid\n",
    "    elif gid.shape == (HX, HY, HZ):\n",
    "        grid = np.transpose(gid, (2, 1, 0))       # -> (HZ,HY,HX)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected GrainId shape: {gid.shape}, expected {(HZ,HY,HX)} (or flatten)\")\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected GrainId ndim: {gid.ndim}\")\n",
    "\n",
    "# 2) 边界检查\n",
    "assert 0 <= HX0 < HX1 <= HX, (HX0, HX1, HX)\n",
    "assert 0 <= HY0 < HY1 <= HY, (HY0, HY1, HY)\n",
    "assert 0 <= HZ0 < HZ1 <= HZ, (HZ0, HZ1, HZ)\n",
    "\n",
    "# 3) 切片并流式写 CSV（避免一次性建 5.9M 行 dataframe）\n",
    "with OUT_CSV.open(\"w\", newline=\"\") as fp:\n",
    "    w = csv.writer(fp, delimiter=\" \")\n",
    "    w.writerow([\"HZ\", \"HY\", \"HX\", \"grain-ID\"])\n",
    "\n",
    "    # 按 hz 一层一层写（每层 (HY1-HY0)*(HX1-HX0) 行）\n",
    "    hx_vals = np.arange(HX0, HX1, dtype=np.int32)\n",
    "    hy_vals = np.arange(HY0, HY1, dtype=np.int32)\n",
    "\n",
    "    for hz in range(HZ0, HZ1):\n",
    "        slab = grid[hz, HY0:HY1, HX0:HX1].astype(np.int64, copy=False)  # shape (hy, hx)\n",
    "        # 逐行写：每行是 (HZ, HY, HX, grain-ID)\n",
    "        for iy, hy in enumerate(hy_vals):\n",
    "            row_gid = slab[iy, :]\n",
    "            # 写这一行的所有 hx\n",
    "            # (如果你想更快，可改成 fp.write 批量拼接字符串；这个版本先清晰稳妥)\n",
    "            for ix, hx in enumerate(hx_vals):\n",
    "                w.writerow([hz, int(hy), int(hx), int(row_gid[ix])])\n",
    "\n",
    "print(\"Wrote:\", OUT_CSV)\n",
    "print(\"Grid dim (HX,HY,HZ) =\", (HX, HY, HZ))\n",
    "print(\"Kept voxels =\", (HX1-HX0)*(HY1-HY0)*(HZ1-HZ0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
